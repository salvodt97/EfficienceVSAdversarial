# EfficienceVSAdversarial

**Error Resiliency and Adversarial Robustness in CNNs: An Empirical Analysis**

This repository contains the code, experiments, and results presented in the following paper:

> M. Barbareschi, S. Barone, V. Casola, and S. Della Torca,  
> *Error Resiliency and Adversarial Robustness in Convolutional Neural Networks: An Empirical Analysis*,  
> IFIP International Internet of Things Conference (IFIP-IoT 2024), Springer, pp. 149â€“160.  
> [https://doi.org/10.1007/978-3-031-57202-3_12](https://doi.org/10.1007/978-3-031-57202-3_12)

## ğŸ“˜ Overview

This work investigates the interplay between **approximate computing** and **adversarial robustness** in Convolutional Neural Networks (CNNs). It includes:

- Construction of Approximate Neural Networks (AxNNs) by replacing exact multipliers with approximate ones;
- Multi-Objective Optimization (via NSGA-II) to select optimal approximate configurations;
- Evaluation of multiple **white-box** (e.g., BIM, PGD, CW, DP) and **black-box** (e.g., One-Pixel) adversarial attacks on both original and approximate models.

## ğŸ—‚ Repository Structure

```
EfficienceVSAdversarial/
â”œâ”€â”€ src/                     # All Python scripts live here
â”‚   â”œâ”€â”€ generate_attacks.py
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â”œâ”€â”€ build_axnn.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Models/                  # All the target models have to be here
â”œâ”€â”€ Results/                 # Output figures, CSVs, statistics
â”‚   â”œâ”€â”€ BlackBoxResults/
â”‚   â””â”€â”€ WhiteBoxResults/
â””â”€â”€ README.md
```

## ğŸ§ª Requirements

- Python â‰¥ 3.8
- TensorFlow
- numpy, pandas, matplotlib
- **inspectnn** ([PyPI link](https://pypi.org/project/inspectnn/))

Install required packages:

```bash
pip install -r requirements.txt
```

## ğŸ§  Models

- **MinNet**: a lightweight CNN
- **ResNet8**, **ResNet24**: standard ResNet variants
- Trained on **CIFAR-10**, using quantization-aware training
- AxNNs are built using 8-bit integer approximate multipliers from the EvoApprox8b library

## ğŸ” Adversarial Attacks

Implemented attacks include:

- **White-box**:
  - PGD (Projected Gradient Descent)
  - BIM (Basic Iterative Method)
  - CW (Carlini & Wagner)
  - DP (DeepFool)
- **Black-box**:
  - One-Pixel Attack (using Differential Evolution)

## ğŸ“Š Results

The `Results/` folder contains:
- Boxplots, PSNR graphs, iteration counts
- Attack success rates in `.csv` format
- Transferability analysis

## ğŸ“„ Citation

If you use this repository, please cite the following paper:

```bibtex
@inproceedings{barbareschi2024error,
  title={Error Resiliency and Adversarial Robustness in Convolutional Neural Networks: An Empirical Analysis},
  author={Barbareschi, Mario and Barone, Salvatore and Casola, Valentina and Della Torca, Salvatore},
  booktitle={IFIP International Internet of Things Conference},
  pages={149--160},
  year={2024},
  organization={Springer},
  doi={10.1007/978-3-031-57202-3_12}
}
```

## ğŸ§° Notes

- All Python scripts are located in the `src/` subdirectory.
- This work makes use of the public `inspectnn` library to analyze internal CNN behaviors.

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the `LICENSE` file for details.

## ğŸ™ Acknowledgments

This work was carried out at the University of Napoli Federico II, with experiments performed in collaboration with the authors' research groups.
